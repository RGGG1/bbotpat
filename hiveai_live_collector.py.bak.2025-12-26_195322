#!/usr/bin/env python3
import asyncio
import json
import math
from datetime import datetime, timezone
from pathlib import Path

import aiohttp

# Centralized token derivative logic (do NOT duplicate formulas elsewhere)
from token_derivatives import compute_action_for_row, compute_pot_roi_frac


# -----------------------------
# v1-style HMI helpers (live)
# -----------------------------
def _clip01(x: float) -> float:
    return max(0.0, min(1.0, float(x)))


def load_v1_hmi_calibration(csv_path: str):
    """
    Loads v1 calibration bounds from the same history file v1 uses.
    Uses rolling 365-day 5%/95% quantiles for:
      - OI (oi_usd)
      - perp_frac = perp_volume / (perp_volume + spot_volume)
      - V_raw = RV_90 / RV_30 (from spot_close)
    """
    try:
        import pandas as pd
        import numpy as np
    except Exception:
        return None

    p = Path(csv_path)
    if not p.exists():
        return None

    df = pd.read_csv(p)
    if df is None or df.empty:
        return None

    required = ("date", "spot_close", "spot_volume", "perp_volume", "oi_usd")
    for c in required:
        if c not in df.columns:
            return None

    df = df.sort_values("date").reset_index(drop=True).copy()
    eps = 1e-9

    # Volatility components like v1
    df["log_ret"] = np.log(df["spot_close"] / df["spot_close"].shift(1))
    df["RV_30"] = df["log_ret"].rolling(30).std() * math.sqrt(365)
    df["RV_90"] = df["log_ret"].rolling(90).std() * math.sqrt(365)
    V_raw = df["RV_90"] / (df["RV_30"] + eps)

    # Perp pressure like v1
    df["perp_frac"] = df["perp_volume"] / (df["perp_volume"] + df["spot_volume"] + eps)

    def rolling_bounds(series, window=365, lo_q=0.05, hi_q=0.95):
        low = series.rolling(window=window, min_periods=window).quantile(lo_q)
        high = series.rolling(window=window, min_periods=window).quantile(hi_q)
        # avoid divide-by-zero
        mask = (high - low).abs() < eps
        high[mask] = low[mask] + eps
        return low, high

    OI_low_s, OI_high_s = rolling_bounds(df["oi_usd"], window=365)
    PF_low_s, PF_high_s = rolling_bounds(df["perp_frac"], window=365)
    V_low_s, V_high_s = rolling_bounds(V_raw, window=365)

    valid = (
        (~OI_low_s.isna()) & (~OI_high_s.isna()) &
        (~PF_low_s.isna()) & (~PF_high_s.isna()) &
        (~V_low_s.isna()) & (~V_high_s.isna())
    )
    if not valid.any():
        return None

    i = int(valid[valid].index[-1])

    return {
        "oi_low": float(OI_low_s.iloc[i]),
        "oi_high": float(OI_high_s.iloc[i]),
        "pf_low": float(PF_low_s.iloc[i]),
        "pf_high": float(PF_high_s.iloc[i]),
        "v_low": float(V_low_s.iloc[i]),
        "v_high": float(V_high_s.iloc[i]),
        "v_raw_last": float(V_raw.iloc[i]),
    }


def compute_hmi_v1_style_live(
    oi_usd_now: float,
    spot_vol_usd_24h: float,
    perp_vol_usd_24h: float,
    calib: dict
) -> float | None:
    """
    v1 weighting:
      HMI = 0.50*OI_score + 0.30*SP_score + 0.20*V_score
    where each score is 0..100 based on rolling 365d quantile bounds.
    """
    if calib is None:
        return None

    eps = 1e-9
    if oi_usd_now is None or spot_vol_usd_24h is None or perp_vol_usd_24h is None:
        return None

    denom = perp_vol_usd_24h + spot_vol_usd_24h + eps
    perp_frac = perp_vol_usd_24h / denom

    oi_score = 100.0 * _clip01((oi_usd_now - calib["oi_low"]) / ((calib["oi_high"] - calib["oi_low"]) + eps))
    sp_score = 100.0 * _clip01((perp_frac - calib["pf_low"]) / ((calib["pf_high"] - calib["pf_low"]) + eps))

    v_raw = calib["v_raw_last"]
    v_score = 100.0 * _clip01((v_raw - calib["v_low"]) / ((calib["v_high"] - calib["v_low"]) + eps))

    return (0.50 * oi_score) + (0.30 * sp_score) + (0.20 * v_score)


# -------------------------
# Paths (write into webroot)
# -------------------------
WEBROOT = Path("/var/www/bbotpat_live")
WEBROOT.mkdir(parents=True, exist_ok=True)

HMI_OUT = WEBROOT / "hmi_latest.json"
PRICES_OUT = WEBROOT / "prices_latest.json"
DOM_BANDS_OUT = WEBROOT / "dom_bands_latest.json"

# IMPORTANT: v1 calibration file
HMI_CALIB = load_v1_hmi_calibration("/root/bbotpat/data/hmi_oi_history.csv")

SUPPLIES_PATHS = [
    Path("/root/bbotpat_live/supplies_latest.json"),
    Path("/root/bbotpat_live/docs/supplies_latest.json"),
    Path("/root/bbotpat/supplies_latest.json"),
    Path("/root/bbotpat/docs/supplies_latest.json"),
]

# Universe used on your site (match your V1 index token set)
TOKENS = ["BTC", "ETH", "BNB", "SOL", "DOGE", "TON", "SUI", "UNI"]
STABLE_HINTS = ("USD",)

BINANCE_SPOT_WS = "wss://stream.binance.com:9443/stream"
BINANCE_FUT_WS = "wss://fstream.binance.com/stream"

SYMBOLS = {t: f"{t.lower()}usdt" for t in TOKENS}  # "btcusdt" etc.

# Output cadence (seconds)
WRITE_EVERY_SEC = 1.0

# OI poll cadence (seconds) — openInterestHist(5m) won't change each second anyway
OI_POLL_EVERY_SEC = 60.0


# -------------------------
# Helpers
# -------------------------
def utc_now_iso():
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")


def band_label_from_hmi(hmi: float) -> str:
    # keep your V1 band labels
    if hmi < 10:
        return "Zombie Apocalypse"
    if hmi < 25:
        return "McDonald's Applications in high demand"
    if hmi < 45:
        return "NGMI"
    if hmi < 50:
        return "Leaning bearish"
    if hmi < 55:
        return "Cautiously bullish"
    if hmi < 75:
        return "It's digital gold"
    if hmi < 90:
        return "Frothy"
    return "It's the future of finance"


def read_supplies():
    for p in SUPPLIES_PATHS:
        if p.exists():
            try:
                js = json.loads(p.read_text())
                supplies = js.get("supplies", js)
                return {k.upper(): float(v.get("circulating_supply", v)) for k, v in supplies.items()}
            except Exception:
                continue
    return {}


def compute_market_caps(supplies):
    mcs = {}
    for t in TOKENS:
        p = spot_price.get(t)
        s = supplies.get(t)
        if p is None or s is None:
            mcs[t] = 0.0
        else:
            mcs[t] = float(p) * float(s)
    return mcs


def compute_btc_dom_vs_token(btc_mc, token_mc):
    if btc_mc <= 0 or token_mc <= 0:
        return None
    return 100.0 * btc_mc / (btc_mc + token_mc)


def read_hourly_ranges():
    # Keep hourly ranges as-is (you said dom/range can stay slower)
    candidates = [
        Path("/var/www/bbotpat/prices_latest.json"),
        Path("/var/www/bbotpat_v2/prices_latest.json"),
        Path("/root/bbotpat/docs/prices_latest.json"),
        Path("/root/bbotpat/docs_v2/prices_latest.json"),
    ]
    for p in candidates:
        if p.exists():
            try:
                js = json.loads(p.read_text())
                rows = js.get("rows", [])
                out = {}
                for r in rows:
                    tok = (r.get("token") or "").upper()
                    rng = r.get("range")
                    if tok and rng:
                        out[tok] = rng
                if out:
                    return out
            except Exception:
                pass
    return {}


def read_dom_bands():
    # If you already generate dom bands elsewhere hourly, mirror them into live webroot
    candidates = [
        Path("/var/www/bbotpat/dom_bands_latest.json"),
        Path("/var/www/bbotpat_v2/dom_bands_latest.json"),
        Path("/root/bbotpat/docs/dom_bands_latest.json"),
        Path("/root/bbotpat/docs_v2/dom_bands_latest.json"),
    ]
    for p in candidates:
        if p.exists():
            try:
                return json.loads(p.read_text())
            except Exception:
                pass
    return None


# -------------------------
# Live state (updated by WS)
# -------------------------
spot_price = {t: None for t in TOKENS}
spot_change_24h = {t: None for t in TOKENS}
spot_quotevol_24h = {t: None for t in TOKENS}  # USDT quote vol (from spot @ticker q)

fut_price = {t: None for t in TOKENS}
fut_quotevol_24h = {t: None for t in TOKENS}  # USDT quote vol (from futures @ticker q)

# Open interest value in USDT (correct unit for v1 calibration oi_usd)
last_btc_oi_usdt_value = None


# -------------------------
# REST fetch: BTC OI value (USDT)
# -------------------------
async def fetch_open_interest_usdt_value(session: aiohttp.ClientSession):
    """
    Uses Binance futures data endpoint:
      /futures/data/openInterestHist
    which returns sumOpenInterestValue (USDT value).
    This matches v1 calibration column name `oi_usd`.
    """
    url = "https://fapi.binance.com/futures/data/openInterestHist"
    params = {"symbol": "BTCUSDT", "period": "5m", "limit": 1}
    async with session.get(url, params=params, timeout=10) as r:
        r.raise_for_status()
        arr = await r.json()
        if not arr:
            return None
        v = arr[-1].get("sumOpenInterestValue")
        if v is None:
            return None
        return float(v)


# -------------------------
# Writers
# -------------------------
async def write_outputs():
    # market caps depend on CoinGecko circulating supplies (you wanted this)
    supplies = read_supplies()
    mcs = compute_market_caps(supplies)
    hourly_ranges = read_hourly_ranges()

    # prices_latest.json (match V1 frontend expectations + action + pot roi)
    rows = []
    btc_mc = mcs.get("BTC", 0.0)

    for t in TOKENS:
        p = spot_price.get(t)
        mc = mcs.get(t, 0.0)
        ch = spot_change_24h.get(t)

        rng = hourly_ranges.get(t, "–")

        btc_dom = None
        if t != "BTC" and not any(x in t for x in STABLE_HINTS):
            btc_dom = compute_btc_dom_vs_token(btc_mc, mc)

        rows.append({
            "token": t,
            "price": p,
            "mc": mc,
            "change_24h": ch,
            "btc_dom": btc_dom,
            "range": rng,

            # CENTRALIZED logic
            "action": compute_action_for_row(t, btc_dom, rng),
            "pot_roi_frac": compute_pot_roi_frac(t, rng, btc_mc, mc, p),
        })

    PRICES_OUT.write_text(json.dumps({
        "timestamp": utc_now_iso(),
        "rows": rows,
    }, indent=2))

    # Mirror dom bands (hourly) if available
    dom_bands = read_dom_bands()
    if dom_bands is not None:
        DOM_BANDS_OUT.write_text(json.dumps(dom_bands, indent=2))

    # hmi_latest.json (v1-style, using correct live inputs)
    oi_usd_now = last_btc_oi_usdt_value
    spot_vol_usd_24h = spot_quotevol_24h.get("BTC")
    perp_vol_usd_24h = fut_quotevol_24h.get("BTC")

    hmi = compute_hmi_v1_style_live(
        oi_usd_now=oi_usd_now,
        spot_vol_usd_24h=spot_vol_usd_24h,
        perp_vol_usd_24h=perp_vol_usd_24h,
        calib=HMI_CALIB,
    )
    if hmi is not None:
        HMI_OUT.write_text(json.dumps({
            "hmi": round(hmi, 1),
            "band": band_label_from_hmi(hmi),
            "exported_at": utc_now_iso(),
        }, indent=2))


# -------------------------
# Websocket consumer
# -------------------------
async def ws_consumer(url, streams, which: str):
    """
    Connect a combined stream WS and update globals.
    We use <symbol>@ticker for both spot + futures.
    """
    params = "/".join(streams)
    full = f"{url}?streams={params}"

    async with aiohttp.ClientSession() as session:
        async with session.ws_connect(full, heartbeat=30) as ws:
            async for msg in ws:
                if msg.type != aiohttp.WSMsgType.TEXT:
                    continue
                try:
                    data = json.loads(msg.data)
                    payload = data.get("data", {})
                    s = (payload.get("s") or "").upper()  # e.g. BTCUSDT
                    if not s.endswith("USDT"):
                        continue
                    tok = s[:-4]  # BTCUSDT -> BTC
                    if tok not in TOKENS:
                        continue

                    # @ticker fields:
                    # c = last price
                    # P = priceChangePercent
                    # q = quote volume (24h) in quote asset units (USDT)
                    c = payload.get("c")
                    P = payload.get("P")
                    q = payload.get("q")

                    if c is not None:
                        if which == "spot":
                            spot_price[tok] = float(c)
                        else:
                            fut_price[tok] = float(c)

                    if P is not None and which == "spot":
                        # keep v1-ish style: percent change as float
                        spot_change_24h[tok] = float(P)

                    if q is not None:
                        if which == "spot":
                            spot_quotevol_24h[tok] = float(q)
                        else:
                            fut_quotevol_24h[tok] = float(q)

                except Exception:
                    # ignore malformed frames
                    continue


# -------------------------
# Loops
# -------------------------
async def oi_poller():
    global last_btc_oi_usdt_value
    async with aiohttp.ClientSession() as session:
        while True:
            try:
                v = await fetch_open_interest_usdt_value(session)
                if v is not None:
                    last_btc_oi_usdt_value = v
            except Exception:
                pass
            await asyncio.sleep(OI_POLL_EVERY_SEC)


async def periodic_flush_outputs():
    while True:
        try:
            await write_outputs()
        except Exception as e:
            print("periodic_flush_outputs error:", repr(e))
        await asyncio.sleep(WRITE_EVERY_SEC)


async def main():
    # Combined streams
    spot_streams = [f"{SYMBOLS[t]}@ticker" for t in TOKENS]
    fut_streams = [f"{SYMBOLS[t]}@ticker" for t in TOKENS]

    await asyncio.gather(
        ws_consumer(BINANCE_SPOT_WS, spot_streams, "spot"),
        ws_consumer(BINANCE_FUT_WS, fut_streams, "futures"),
        oi_poller(),
        periodic_flush_outputs(),
    )


if __name__ == "__main__":
    asyncio.run(main())
